{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "------------------- Input Data ---------------\n",
      "==============================================\n",
      "\n",
      "    # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  \\\n",
      "0        4.620      30.3   -356.00     15.60      26.3      1.0700   \n",
      "1       28.800      33.1     32.00     25.80      22.8      6.5500   \n",
      "2        8.900      29.4   -416.00     16.70      23.7     79.9000   \n",
      "3       14.900      31.6   -143.00     19.80      24.3     -0.5840   \n",
      "4       28.300      31.3     45.20     27.30      24.5     34.8000   \n",
      "5       31.000      30.9     29.60     28.50      24.0      1.6500   \n",
      "6       10.800      21.0     44.70      4.87      28.1      2.1400   \n",
      "7       17.800      27.8   -102.00     16.90      26.9     -3.2100   \n",
      "8       11.500      29.7     34.90     10.20      26.9    -38.0000   \n",
      "9        8.910      29.2   -314.00      6.51      30.9     -1.8800   \n",
      "10       5.210      28.4     18.50      3.66      22.6     -0.1190   \n",
      "11      13.300      30.4   -149.00     11.80      28.3      3.0300   \n",
      "12      30.100      32.7     29.40     28.30      24.3     -6.0500   \n",
      "13      19.300      31.7     -4.56     23.80      32.9     -3.4100   \n",
      "14      28.800      31.8     30.10     26.90      21.8     -0.3550   \n",
      "15      12.700      23.8   -193.00     11.10      27.6     -3.7200   \n",
      "16       0.425      34.9     53.90    -11.90      22.6     12.4000   \n",
      "17      28.900      30.8     29.40     27.40      25.1     -7.8600   \n",
      "18     -14.100      21.9   -946.00      8.93      22.6      0.0289   \n",
      "19       8.740      27.6   -399.00     15.00      28.1     -5.8600   \n",
      "\n",
      "    mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  \\\n",
      "0        0.411     -15.700       2.060       3.150  ...      23.50      20.30   \n",
      "1        1.680       2.880       3.830      -4.820  ...     -23.30     -21.80   \n",
      "2        3.360      90.200      89.900       2.030  ...     462.00    -233.00   \n",
      "3       -0.284       8.820       2.300      -1.970  ...     299.00    -243.00   \n",
      "4       -5.790       3.060      41.400       5.520  ...      12.00      38.10   \n",
      "5        1.540       3.830       1.870      -1.210  ...      -1.48      30.20   \n",
      "6        1.020      13.200       1.160      -4.390  ...     -15.60     -41.00   \n",
      "7       -1.950       9.800      -3.240      -0.955  ...    -177.00      32.80   \n",
      "8       -1.650       3.890     -33.500      -3.300  ...      -8.38      38.70   \n",
      "9        1.900      11.900      -3.600       5.700  ...     226.00     -81.80   \n",
      "10      -2.350       5.070       0.461      -4.260  ...      -4.25     -47.80   \n",
      "11       0.895      -4.520       1.720      -0.633  ...       6.11      20.00   \n",
      "12      -3.940       1.690      -3.570       6.020  ...      12.00     -21.50   \n",
      "13       0.677      46.600       6.800       3.890  ...     244.00    -144.00   \n",
      "14       0.465       3.820       0.442      -1.830  ...       8.68     -28.70   \n",
      "15       2.050      19.800      -0.804      -2.870  ...     543.00    -197.00   \n",
      "16      -2.720      -4.860       5.290      -1.040  ...      18.60      -6.22   \n",
      "17       1.020       0.499      -8.500      -1.260  ...     -33.10      -0.52   \n",
      "18       1.280      16.400       9.200       4.260  ...     821.00    -423.00   \n",
      "19      -1.880       9.100       2.070      -6.290  ...     326.00    -185.00   \n",
      "\n",
      "    fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  \\\n",
      "0       20.30      23.50    -215.00     280.00    -162.00    -162.00   \n",
      "1      -21.80     -23.30     182.00       2.57     -31.60     -31.60   \n",
      "2     -233.00     462.00    -267.00     281.00    -148.00    -148.00   \n",
      "3     -243.00     299.00     132.00     -12.40       9.53       9.53   \n",
      "4       38.10      12.00     119.00     -17.60      23.90      23.90   \n",
      "5       30.20      -1.48     134.00       3.59     -12.70     -12.70   \n",
      "6      -41.00     -15.60      89.50      40.60     -55.20     -55.20   \n",
      "7       32.80    -177.00    -417.00     384.00    -186.00    -186.00   \n",
      "8       38.70      -8.38     115.00      -7.00       3.20       3.20   \n",
      "9      -81.80     226.00       1.84      99.40     -40.30     -40.30   \n",
      "10     -47.80      -4.25      99.60      11.20      41.70      41.70   \n",
      "11      20.00       6.11     -53.00     176.00    -167.00    -167.00   \n",
      "12     -21.50      12.00     152.00      23.60     -16.40     -16.40   \n",
      "13    -144.00     244.00      18.50     -14.80      10.30      10.30   \n",
      "14     -28.70       8.68     157.00     -17.30       4.93       4.93   \n",
      "15    -197.00     543.00    -499.00     427.00    -161.00    -161.00   \n",
      "16      -6.22      18.60      47.90     -21.20     -61.50     -61.50   \n",
      "17      -0.52     -33.10      95.10       1.83      15.80      15.80   \n",
      "18    -423.00     821.00    -671.00     678.00    -249.00    -249.00   \n",
      "19    -185.00     326.00    -106.00     156.00     -43.40     -43.40   \n",
      "\n",
      "    fft_749_b     label  \n",
      "0      280.00  NEGATIVE  \n",
      "1        2.57   NEUTRAL  \n",
      "2      281.00  POSITIVE  \n",
      "3      -12.40  POSITIVE  \n",
      "4      -17.60   NEUTRAL  \n",
      "5        3.59   NEUTRAL  \n",
      "6       40.60  POSITIVE  \n",
      "7      384.00  NEGATIVE  \n",
      "8       -7.00   NEUTRAL  \n",
      "9       99.40  NEGATIVE  \n",
      "10      11.20  POSITIVE  \n",
      "11     176.00  NEGATIVE  \n",
      "12      23.60   NEUTRAL  \n",
      "13     -14.80  NEGATIVE  \n",
      "14     -17.30   NEUTRAL  \n",
      "15     427.00  NEGATIVE  \n",
      "16     -21.20  POSITIVE  \n",
      "17       1.83   NEUTRAL  \n",
      "18     678.00  NEGATIVE  \n",
      "19     156.00  NEGATIVE  \n",
      "\n",
      "[20 rows x 2549 columns]\n",
      "=======================================================\n",
      "------------------  Checking Missing Values -------==--\n",
      "======================================================\n",
      "\n",
      "# mean_0_a    0\n",
      "mean_1_a      0\n",
      "mean_2_a      0\n",
      "mean_3_a      0\n",
      "mean_4_a      0\n",
      "             ..\n",
      "fft_746_b     0\n",
      "fft_747_b     0\n",
      "fft_748_b     0\n",
      "fft_749_b     0\n",
      "label         0\n",
      "Length: 2549, dtype: int64\n",
      "-----------------------------------------------------------\n",
      "================== Before label Encoding ==================\n",
      "-----------------------------------------------------------\n",
      "\n",
      "0    NEGATIVE\n",
      "1     NEUTRAL\n",
      "2    POSITIVE\n",
      "3    POSITIVE\n",
      "4     NEUTRAL\n",
      "5     NEUTRAL\n",
      "6    POSITIVE\n",
      "7    NEGATIVE\n",
      "8     NEUTRAL\n",
      "9    NEGATIVE\n",
      "Name: label, dtype: object\n",
      "-----------------------------------------------------------\n",
      "================== After label Encoding ==================\n",
      "-----------------------------------------------------------\n",
      "\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "4    1\n",
      "5    1\n",
      "6    2\n",
      "7    0\n",
      "8    1\n",
      "9    0\n",
      "Name: label, dtype: int32\n",
      "-----------------------------------------------------------\n",
      "=================== Data Splitting  =======================\n",
      "-----------------------------------------------------------\n",
      "\n",
      "The total No.of original data: 2132\n",
      "\n",
      "The total No.of Test data: 427\n",
      "\n",
      "The total No.of Train data: 1705\n",
      "\n",
      "-----------------------------------------------------------\n",
      "================== Random Forest   ========================\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Accuracy is 97.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#============================= IMPORT LIBRARIES =============================\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#============================= DATA SELECTION ==============================\n",
    "\n",
    "dataframe=pd.read_csv(\"m.csv\")\n",
    "print(\"==============================================\")\n",
    "print(\"------------------- Input Data ---------------\")\n",
    "print(\"==============================================\")\n",
    "print()\n",
    "print(dataframe.head(20))\n",
    "\n",
    "#============================= PREPROCESSING ==============================\n",
    "\n",
    "#==== checking missing values ====\n",
    "\n",
    "print(\"=======================================================\")\n",
    "print(\"------------------  Checking Missing Values -------==--\")\n",
    "print(\"======================================================\")\n",
    "print()\n",
    "print(dataframe.isnull().sum())\n",
    "\n",
    "\n",
    "dataframee=dataframe[['# mean_0_a','mean_1_a','mean_2_a','mean_3_a','mean_4_a','label']]\n",
    "\n",
    "\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"================== Before label Encoding ==================\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "print(dataframee['label'].head(10))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"================== After label Encoding ==================\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "dataframee['label']= label_encoder.fit_transform(dataframee['label'])\n",
    "\n",
    "print(dataframee['label'].head(10))\n",
    "\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"=================== Data Splitting  =======================\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "X = dataframee.drop('label', axis = 1)\n",
    "y = dataframee['label']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(\"The total No.of original data:\",X.shape[0] )\n",
    "print()\n",
    "print(\"The total No.of Test data:\",X_test.shape[0] )\n",
    "print()\n",
    "print(\"The total No.of Train data:\",X_train.shape[0] )\n",
    "print()\n",
    "\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"================== Random Forest   ========================\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(y_test, model.predict(X_test))\n",
    "print(f\"Accuracy is {round(accuracy_score(y_test, model.predict(X_test))*100,2)}\")\n",
    "print()\n",
    "\n",
    "import pickle\n",
    "pickle.dump(model, open('eeg.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 97.89\n",
      "\n",
      "The MSE value is 0.0702576112412178\n",
      " The MAE value is 0.03747072599531616\n",
      "The RMSE Value is 0.2650615235020311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "confusion_matrix(y_test, model.predict(X_test))\n",
    "print(f\"Accuracy is {round(accuracy_score(y_test, model.predict(X_test))*100,2)}\")\n",
    "print()\n",
    "from sklearn import metrics\n",
    "mse=metrics.mean_squared_error(y_test,model.predict(X_test))\n",
    "print(\"The MSE value is\",mse)\n",
    "import numpy as np\n",
    "rmse=np.sqrt(mse)\n",
    "print(\" The MAE value is\",metrics.mean_absolute_error(y_test,model.predict(X_test)))\n",
    "print(\"The RMSE Value is\",rmse)\n",
    "\n",
    "\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "========================== CNN   ===========================\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 5, 1)]            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 4, 2)              6         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 2, 2)              0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 1s 6ms/step - loss: 98.6259 - mse: 27463.1602 - mae: 98.6259 - accuracy: 0.0035\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 95.3611 - mse: 25783.0039 - mae: 95.3611 - accuracy: 0.0047\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 92.1625 - mse: 24184.4297 - mae: 92.1625 - accuracy: 0.0059\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 89.0336 - mse: 22660.3516 - mae: 89.0336 - accuracy: 0.0070\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 85.9755 - mse: 21200.7266 - mae: 85.9755 - accuracy: 0.0082\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------\")\n",
    "print(\"========================== CNN   ===========================\")\n",
    "print(\"-----------------------------------------------------------\")\n",
    "print()\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Input\n",
    "inp =  Input(shape=(5,1))\n",
    "conv = Conv1D(filters=2, kernel_size=2)(inp)\n",
    "pool = MaxPool1D(pool_size=2)(conv)\n",
    "flat = Flatten()(pool)\n",
    "dense = Dense(1)(flat)\n",
    "model = Model(inp, dense)\n",
    "model.compile(loss='mae', optimizer='adam',metrics=['mse','mae','accuracy'])\n",
    "\n",
    "x=np.expand_dims(X_train, axis=2)\n",
    "Y=np.expand_dims(y_train,axis=1)\n",
    "\n",
    "print(model.summary())\n",
    "history = model.fit(x, Y, epochs=5, batch_size=200, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 981us/step - loss: 84.2377 - mse: 20401.0020 - mae: 84.2377 - accuracy: 0.0082\n",
      "The MSE Value is  20401.001953125\n",
      "\n",
      "54/54 [==============================] - 0s 849us/step - loss: 84.2377 - mse: 20401.0020 - mae: 84.2377 - accuracy: 0.0082\n",
      "The MAE Value is  84.2376937866211\n",
      "\n",
      "54/54 [==============================] - 0s 849us/step - loss: 84.2377 - mse: 20401.0020 - mae: 84.2377 - accuracy: 0.0082\n",
      "The Accuracy Value is  0.00821114331483841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_mse=model.evaluate(x,Y,verbose=1)[1]\n",
    "print(\"The MSE Value is \",cnn_mse)\n",
    "print()\n",
    "cnn_mae=model.evaluate(x,Y,verbose=1)[0]\n",
    "print(\"The MAE Value is \",cnn_mae)\n",
    "print()\n",
    "cnn_acc=model.evaluate(x,Y,verbose=1)[3]\n",
    "print(\"The Accuracy Value is \",cnn_acc )\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('CNN')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
